{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross transfer and test/train size expts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prtos/anaconda3/envs/invivo/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from collections import defaultdict\n",
    "mpl.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hash(depth=None, type=None):\n",
    "    \"\"\"Utility method to make a multilevel dict\"\"\"\n",
    "    if (depth, type) == (None, None):\n",
    "        return defaultdict(makehash)\n",
    "    elif depth == 0:\n",
    "        return defaultdict(type)\n",
    "    else:\n",
    "        return defaultdict(partial(makehash, depth - 1, type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metalearn.datasets.loaders import load_dataset\n",
    "from metalearn.models.factory import ModelFactory\n",
    "from metalearn.utils.metric import mse, vse, r2, pcc\n",
    "from collections import OrderedDict\n",
    "\n",
    "def unflatten(dictionary):\n",
    "    resultDict = dict()\n",
    "    for key, value in dictionary.items():\n",
    "        parts = key.split(\".\")\n",
    "        d = resultDict\n",
    "        for part in parts[:-1]:\n",
    "            if part not in d:\n",
    "                d[part] = dict()\n",
    "            d = d[part]\n",
    "        d[parts[-1]] = value\n",
    "    return resultDict\n",
    "\n",
    "def save_stats(scores_dict, outfile=sys.stdout):\n",
    "    metrics = list(scores_dict.keys())\n",
    "    metrics.remove('size')\n",
    "    metrics.remove('name')\n",
    "    names = scores_dict['name']\n",
    "    sizes = scores_dict['size']\n",
    "\n",
    "    results = [\n",
    "        OrderedDict(\n",
    "            ([('name', names[idx]), ('size', sizes[idx])] +\n",
    "             [(metric_name + aggregator.__name__, aggregator(scores_dict[metric_name][idx]))\n",
    "              for metric_name in metrics for aggregator in [np.mean, np.median, np.std]]\n",
    "             )\n",
    "        ) for idx in names\n",
    "    ]\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv(outfile, index=False, sep='\\t')\n",
    "    return results\n",
    "    \n",
    "def load_model_and_metatest(folder, return_params=False):\n",
    "    param_file = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('_params.json')]\n",
    "    model_file = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('_ckp.ckp')]\n",
    "    if len(param_file) == 0 or len(model_file) == 0:\n",
    "        return \n",
    "    param_file = param_file[0]\n",
    "    model_file = model_file[0]\n",
    "    \n",
    "    with open(param_file) as fd:\n",
    "        params = json.load(fd)\n",
    "        \n",
    "    params = unflatten(params)\n",
    "    model_name, model_params = params['model_name'], params['model_params']\n",
    "    dataset_name, dataset_params = params['dataset_name'], params['dataset_params']\n",
    "    model = ModelFactory()(model_name, **model_params)\n",
    "    model.load(model_file)\n",
    "    _, _, meta_test = load_dataset(dataset_name, **dataset_params)\n",
    "    if return_params:\n",
    "        return model, meta_test, params\n",
    "    return model, meta_test\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expts_changing_size(folder, res_tag=''):\n",
    "    model, meta_test, params = load_model_and_metatest(folder, return_params=True)\n",
    "    dataset_name, dataset_params = params['dataset_name'], params['dataset_params']\n",
    "    orig_k = meta_test.dataset.max_examples_per_episode\n",
    "    for k in [5, 10, 20, 40, 60, 80, 100]:\n",
    "        meta_test.dataset.max_examples_per_episode = k\n",
    "        dataset_params.update(dict(max_examples_per_episode=k))\n",
    "        _, _, meta_test = load_dataset(dataset_name, **dataset_params)\n",
    "        \n",
    "        scores = model.evaluate(meta_test, metrics=[mse, vse, r2, pcc])\n",
    "        result_fname = f'{res_tag}_me_{orig_k}_to_{k}_res.csv'\n",
    "        with open(result_fname, \"w\") as outfile:\n",
    "            results = save_stats(scores, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expts_cross_transfer(folder_1, folder_2, tag_1, tag_2):\n",
    "    model1, metatest1 = load_model_and_metatest(folder_1, return_params=False)\n",
    "    model2, metatest2 = load_model_and_metatest(folder_2, return_params=False)\n",
    "    \n",
    "    scores = model1.evaluate(metatest2, metrics=[mse, vse, r2, pcc])\n",
    "    result_fname = f'cross_transfert_{tag_1}_to_{tag_2}_res.csv'\n",
    "    with open(result_fname, \"w\") as outfile:\n",
    "        results = save_stats(scores, outfile)\n",
    "\n",
    "    scores = model2.evaluate(metatest1, metrics=[mse, vse, r2, pcc])\n",
    "    result_fname = f'cross_transfert_f{tag_2}_{tag_1}_res.csv'\n",
    "    with open(result_fname, \"w\") as outfile:\n",
    "        results = save_stats(scores, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iscb-2019-01-27-17-26-53-249\n",
      "iscb-2019-01-27-17-27-37-056\n",
      "iscb-2019-01-27-17-27-14-607\n",
      "iscb-2019-01-27-17-27-03-795\n",
      "iscb-2019-01-27-17-27-25-825\n",
      "iscb-2019-01-27-17-28-06-442\n",
      "iscb-2019-01-27-17-26-47-923\n",
      "iscb-2019-01-27-17-26-58-498\n",
      "iscb-2019-01-27-17-27-31-422\n",
      "iscb-2019-01-27-17-27-54-444\n",
      "iscb-2019-01-27-17-27-42-930\n",
      "iscb-2019-01-27-17-27-20-081\n",
      "iscb-2019-01-27-17-27-09-179\n",
      "iscb-2019-01-27-17-27-48-661\n",
      "iscb-2019-01-27-17-28-00-450\n",
      "iscb-2019-01-27-17-28-12-429\n"
     ]
    }
   ],
   "source": [
    "res_folder = '/home/prtos/.invivo/invivoai-sagemaker-artifacts/iscb-expts4/'\n",
    "expts_folders = os.listdir(res_folder)\n",
    "for ef in expts_folders:\n",
    "    print(ef)\n",
    "    expts_changing_size(os.path.join(res_folder, ef, 'output/model'), res_tag=ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adfb08b9d3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m expts_cross_tranfer(os.path.join(pubchem_folder, 'output/model'),\n\u001b[1;32m     25\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchembl_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output/model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     'pubchem', 'chembl')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5b1764847612>\u001b[0m in \u001b[0;36mexpts_cross_tranfer\u001b[0;34m(folder_1, folder_2, tag_1, tag_2)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetatest2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'cross_transfert_{tag1}_to_{tag2}_res.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tag1' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from ivbase.utils.datacache import DataCache\n",
    "import click\n",
    "import shutil\n",
    "\n",
    "def extract_all_model_archives(dir_path, rem_fail=False):\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for fname in files:\n",
    "            fpath = os.path.join(root, fname)\n",
    "            dir_name = fpath[:-7]\n",
    "            if fname.endswith('.tar.gz'):\n",
    "                tar = tarfile.open(fpath, 'r:gz')\n",
    "                tar.extractall(path=dir_name, )\n",
    "                tar.close()\n",
    "            if os.path.isdir(dir_name):\n",
    "                if rem_fail and os.path.exists(os.path.join(dir_name, 'failure')):\n",
    "                    shutil.rmtree(dir_name, ignore_errors=True)\n",
    "                    \n",
    "datacache = DataCache('/home/prtos/.invivo')\n",
    "chembl_folder = datacache.get_dir(\"s3://invivoai-sagemaker-artifacts/iscb-expts3/iscb-2019-01-26-09-19-02-877\")\n",
    "pubchem_folder = datacache.get_dir(\"s3://invivoai-sagemaker-artifacts/iscb-expts3/iscb-2019-01-26-09-19-48-642\")\n",
    "extract_all_model_archives(os.path.dirname(chembl_folder))\n",
    "expts_cross_transfer(os.path.join(pubchem_folder, 'output/model'),\n",
    "                    os.path.join(chembl_folder, 'output/model'), \n",
    "                    'pubchem', 'chembl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invivo",
   "language": "python",
   "name": "invivo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
