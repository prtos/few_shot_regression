Sat Feb 17 15:43:27 EST 2018
/home/ptossou/env/bin/python
37 38
{'dataset_name': 'mhc_pan_a', 'eval_params': None, 'arch': 'cnn', 'fit_params': {'lr': 0.001, 'n_epochs_learner': 2, 'embedding_size': 20, 'lr_learner': 0.01, 'pooling_len': 2, 'normalize_features': True, 'cnn_sizes': [128, 128], 'kernel_size': 2}, 'algo': 'maml', 'max_examples_per_episode': 10}
Epoch 1/1000Epoch 1/1000 ETA 614s Step 1/31: loss: 43.347794Epoch 1/1000 ETA 365s Step 2/31: loss: 43.380283Epoch 1/1000 ETA 279s Step 3/31: loss: 42.583858Epoch 1/1000 ETA 230s Step 4/31: loss: 42.030590Epoch 1/1000 ETA 200s Step 5/31: loss: 41.342633Epoch 1/1000 ETA 180s Step 6/31: loss: 39.651656Epoch 1/1000 ETA 163s Step 7/31: loss: 38.079789Epoch 1/1000 ETA 150s Step 8/31: loss: 36.556825Epoch 1/1000 ETA 138s Step 9/31: loss: 34.676207Epoch 1/1000 ETA 128s Step 10/31: loss: 32.805526Epoch 1/1000 ETA 119s Step 11/31: loss: 30.928934Epoch 1/1000 ETA 111s Step 12/31: loss: 29.182274Epoch 1/1000 ETA 103s Step 13/31: loss: 27.521256Epoch 1/1000 ETA 96s Step 14/31: loss: 26.158854Epoch 1/1000 ETA 89s Step 15/31: loss: 24.979016Epoch 1/1000 ETA 83s Step 16/31: loss: 23.984897Epoch 1/1000 ETA 77s Step 17/31: loss: 23.176839Epoch 1/1000 ETA 71s Step 18/31: loss: 22.390438Epoch 1/1000 ETA 65s Step 19/31: loss: 21.660783Epoch 1/1000 ETA 59s Step 20/31: loss: 20.960475Epoch 1/1000 ETA 54s Step 21/31: loss: 20.310870Epoch 1/1000 ETA 48s Step 22/31: loss: 19.722259Epoch 1/1000 ETA 43s Step 23/31: loss: 19.262121Epoch 1/1000 ETA 37s Step 24/31: loss: 18.825323Epoch 1/1000 ETA 32s Step 25/31: loss: 18.438917Epoch 1/1000 ETA 26s Step 26/31: loss: 18.023459Epoch 1/1000 ETA 21s Step 27/31: loss: 17.632315Epoch 1/1000 ETA 16s Step 28/31: loss: 17.269327Epoch 1/1000 ETA 10s Step 29/31: loss: 16.897730Epoch 1/1000 ETA 5s Step 30/31: loss: 16.596295Epoch 1/1000 ETA 0s Step 31/31: loss: 16.300072Epoch 1/1000 279.63s Step 31/31: loss: 16.300072, val_loss: 7.188142
Epoch 2/1000Epoch 2/1000 ETA 159s Step 1/31: loss: 8.091602Epoch 2/1000 ETA 144s Step 2/31: loss: 7.554650Epoch 2/1000 ETA 135s Step 3/31: loss: 7.693506Epoch 2/1000 ETA 127s Step 4/31: loss: 7.832357Epoch 2/1000 ETA 121s Step 5/31: loss: 7.934974Epoch 2/1000 ETA 115s Step 6/31: loss: 7.768428Epoch 2/1000 ETA 110s Step 7/31: loss: 7.691141Epoch 2/1000 ETA 105s Step 8/31: loss: 7.553206Epoch 2/1000 ETA 101s Step 9/31: loss: 7.573967Epoch 2/1000 ETA 97s Step 10/31: loss: 7.489055Epoch 2/1000 ETA 92s Step 11/31: loss: 7.453665Epoch 2/1000 ETA 87s Step 12/31: loss: 7.455116Epoch 2/1000 ETA 83s Step 13/31: loss: 7.395578Epoch 2/1000 ETA 78s Step 14/31: loss: 7.392485Epoch 2/1000 ETA 74s Step 15/31: loss: 7.386558Epoch 2/1000 ETA 70s Step 16/31: loss: 7.327296Epoch 2/1000 ETA 65s Step 17/31: loss: 7.329776Epoch 2/1000 ETA 60s Step 18/31: loss: 7.312505Epoch 2/1000 ETA 56s Step 19/31: loss: 7.290652Epoch 2/1000 ETA 51s Step 20/31: loss: 7.275140Epoch 2/1000 ETA 46s Step 21/31: loss: 7.218865Epoch 2/1000 ETA 42s Step 22/31: loss: 7.200082Epoch 2/1000 ETA 37s Step 23/31: loss: 7.164934Epoch 2/1000 ETA 32s Step 24/31: loss: 7.154920Epoch 2/1000 ETA 28s Step 25/31: loss: 7.130858Epoch 2/1000 ETA 23s Step 26/31: loss: 7.099009Epoch 2/1000 ETA 19s Step 27/31: loss: 7.100896Epoch 2/1000 ETA 14s Step 28/31: loss: 7.093650Epoch 2/1000 ETA 9s Step 29/31: loss: 7.101061Epoch 2/1000 ETA 5s Step 30/31: loss: 7.107484Epoch 2/1000 ETA 0s Step 31/31: loss: 7.085822